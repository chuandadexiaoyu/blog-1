# Making your API more available

I spoke recently at a Javascript conference in Lisbon Portugal about a design problem that I think is obvious yet frequently overlooked. That is, almost every program that consumes an API over a network is provided with only a single end point to connect to. This inevitably becomes a [Single Point of Failure][0].

At [Nodejitsu][1], we have a deployment tool called [Jitsu][2]. It has a good User Experience and gets the job done. But there is a problem, it only knows about a single API end point (api.nodejitsu.com) and that API isn't up and running 100% of the time. Like anyone else, we have scheduled and unscheduled downtime. During these times, people attempting to deploy applications experience failures.

## The traditional approach

The approach to achieving availability usually starts off something like this...
		
1. Use a processes monitor like [monit][3], [forever][4] or [upstart][5]. If the process goes down, send an alert and try to bring it back up. This can be a futile cycle.

2. Gather statistics on the machine that is running processes using something like [New Relic][6] and send attempt to forecast problems, hope someone is watching or send an alert to someone at 3am. Maybe you write a clever script to talk to a provisioning API, etc.

3. Cluster the machines that run the process and then load balance them. Obviously, if the balancer falls down the clusters are useless.

4. Pay for a DNS failover [service][7]. This is particularly  effective for your customer facing websites since browsers have no built in recourse for connection failures.

So far this is a lot of vertical reinforcement. Mostly by gluing together 3rd party solutions. There's nothing wrong with that, but we haven't exhausted all of our options.

*Side Note* Some of these tools are great individually. However, making them work in concert is quite costly. All of the custom scripts and various support programs needed to glue them together is a cost/risk that feels like an [elephant in the room][8]. At Nodejitsu we mitigated this cost/risk by developing a cohesive, single technology stack. One that addresses distributed monitoring, provisioning, configuration management, etc. Most importantly, the various parts work as well together as they do individually.

## The distributed approach

API clients can be smarter. They don't have to rely on third party services. They can take on more responsibility. Rather than failing when they can't connect, they can come bundled with an updatable cache of API endpoints. Consider a configuration where each endpoint is an instance of the API residing in a different data center.

```json
  "api": {
    "hosts": [
      {
        "protocol": "https",
        "address": "127.0.0.1",
        "port": 8001,
        "responsive": true
      },
      {
        "protocol": "https",
        "address": "127.0.0.1",
        "port": 8002,
        "responsive": true
      },
      {
        "protocol": "https",
        "address": "127.0.0.1",
        "port": 8003,
        "responsive": true
      },
      {
        "protocol": "https",
        "address": "127.0.0.1",
        "port": 8004,
        "responsive": true
      }
    ]
  },
```



[0]:http://en.wikipedia.org/wiki/Single_point_of_failure
[1]:http://nodejitsu.com
[2]:https://github.com/nodejitsu/jitsu
[3]:http://mmonit.com/monit/
[4]:https://github.com/nodejitsu/forever
[5]:http://upstart.ubuntu.com/
[6]:https://newrelic.com/
[7]:http://dyn.com/dns/dynect-managed-dns/active-failover/
[8]:http://en.wikipedia.org/wiki/Elephant_in_the_room
